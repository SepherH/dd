# 臺中市交通事件裁決處酒駕累犯資料爬取分析

## 網站資料結構分析

**網站 URL**: https://www.traffic.taichung.gov.tw/unit/form/index.asp?Parser=2,18,591

### 資料發布特點
1. 網站按照週期（大約每週）更新酒駕及拒測累犯名單
2. 歷史資料保存在分頁機制下，總共約15頁
3. 每個發布日期對應一個獨立的PDF檔案，如「114年7月3日公布酒(毒)駕及拒測累犯名單」

### PDF資料結構
從分析的PDF內容來看，資料包含以下欄位：
- 序號
- 姓名
- 違規日（格式：年/月/日，如111/7/11，使用民國年）
- 違規條款（如第35條第3項）
- 違規地點（如沙鹿區中清路六段489號）
- 違規事實（如「汽機車駕駛人駕駛汽機車，於十年內酒精濃度超過規定標準第2次」）
- 照片（欄位存在，但內容不明確）

### 資料解析挑戰
1. **跨行資料**：部分資料項（如違規事實）可能跨越多行
2. **格式不一**：地址和違規描述可能格式不統一
3. **PDF格式**：資料以PDF形式發布，需要特殊處理
4. **分頁問題**：需要處理網站的分頁機制
5. **歷史資料**：需要爬取和處理多個歷史PDF文件

## 技術解決方案

### 1. 爬蟲策略
1. **鏈接收集**：
   - 使用Cheerio或類似工具解析主頁面HTML
   - 提取所有PDF檔案連結
   - 建立鏈接清單，記錄已爬取和待爬取的PDF

2. **資料獲取**：
   - 分頁處理：實現翻頁機制，依次訪問所有頁面
   - PDF下載：使用Axios或fetch下載PDF檔案
   - 檔案管理：建立適當的檔案命名和存儲結構

### 2. PDF資料解析
1. **使用PyPDF2或pdf.js解析PDF**：
   - 提取文本內容
   - 識別表格結構
   - 處理字體和排版問題

2. **結構化資料處理**：
   - 正則表達式匹配資料項
   - 處理跨行文本合併
   - 標準化日期和地址格式

3. **資料清洗**：
   - 移除不必要的頁眉頁腳
   - 修正可能的OCR錯誤
   - 標準化特殊字符和空白

### 3. OpenAI API整合
1. **文本理解與結構化**：
   - 使用OpenAI API來理解非標準化文本
   - 將自由格式描述轉換為結構化資料
   - 解決跨行和格式不一致問題

2. **名稱和地址標準化**：
   - 統一地址格式
   - 處理同名不同人情況
   - 識別特殊標記（如無照駕駛）

### 4. 資料庫設計
1. **主要資料表結構**：
   ```sql
   CREATE TABLE taichung_dui_offenders (
       id INT AUTO_INCREMENT PRIMARY KEY,
       name VARCHAR(100) CHARACTER SET utf8mb4,
       violation_date DATE,
       violation_article VARCHAR(100),
       violation_location TEXT CHARACTER SET utf8mb4,
       violation_description TEXT CHARACTER SET utf8mb4,
       has_photo BOOLEAN,
       publish_date DATE,
       source_url VARCHAR(255),
       created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
       updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
   );
   ```

2. **關聯資料表**：
   - 建立違規類型參考表
   - 建立地區參考表
   - 考慮建立姓名索引表（處理同名問題）

### 5. 自動化實現
1. **排程任務**：
   - 使用Node.js的cron設定每週執行一次
   - 檢查新發布的資料並更新

2. **監控與錯誤處理**：
   - 記錄爬取過程日誌
   - 發送錯誤通知
   - 自動重試失敗的爬取任務

3. **增量更新機制**：
   - 比對資料，只處理新資料
   - 避免重複爬取和存儲

## 實現步驟

1. **建立爬蟲框架**：
   - 實現網頁爬取類別
   - 實現PDF下載功能
   - 實現分頁處理機制

2. **開發PDF解析器**：
   - 建立通用PDF文本提取功能
   - 開發表格結構識別算法
   - 實現資料項映射功能

3. **整合OpenAI處理**：
   - 建立API呼叫服務
   - 定義提示詞和模型參數
   - 實現回應解析和結構化

4. **資料庫操作**：
   - 建立連接和遷移腳本
   - 實現CRUD操作
   - 優化查詢性能

5. **測試與調整**：
   - 單元測試各個模組
   - 整合測試完整流程
   - 性能測試和優化

## 預計面臨的挑戰

1. **資料格式變更**：網站可能隨時變更資料發布格式或結構
2. **PDF結構不一致**：不同時期發布的PDF格式可能有差異
3. **中文字元編碼**：處理UTF-8和其他編碼問題
4. **爬蟲封鎖**：網站可能實施爬蟲限制
5. **資料完整性**：確保所有資料被正確提取和解析

## 解決方案
1. **自適應解析器**：設計能適應不同格式變化的解析器
2. **異常檢測**：實現異常資料檢測機制
3. **多編碼支援**：確保程式能正確處理各種編碼
4. **爬蟲策略**：實現請求間隔和UA隨機化
5. **資料驗證**：實現多層次的資料驗證流程

## 下一步行動
1. 開發基礎爬蟲框架，測試從主頁獲取PDF連結
2. 實現單個PDF的下載和解析
3. 設計和建立資料庫結構
4. 實現OpenAI API整合處理複雜文本
5. 開發完整的爬蟲-解析-存儲流程
